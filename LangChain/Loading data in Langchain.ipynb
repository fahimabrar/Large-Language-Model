{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1379f614",
   "metadata": {},
   "source": [
    "### Load pdfs as Text\n",
    "using pypdfloader inside Langcahin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebbb3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"transformers_survey.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fdcf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the pdf is a 22 page long research article\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318b8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_page = pages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c153b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Open 3 (2022) 111–132\n",
      "112T. Lin et al.\n",
      "Fig. 1. Overview of vanilla Transformer architecture.\n",
      "2. Background\n",
      "2.1. Vanilla Transformer\n",
      "The vanilla Transformer (Vaswani et al., 2017) is a sequence-to-\n",
      "sequence model and consists of an encoder and a decoder, each of\n",
      "which is a stack of 𝐿identical blocks. Each encoder block is mainly\n",
      "composed of a multi-head self-attention module and a position-wise\n",
      "feed-forward network (FFN). For building a deeper model, a residual\n",
      "connection (He et al., 2016) is employed around each module, followed\n",
      "by Layer Normalization (Ba et al., 2016) module. Compared to the\n",
      "encoder blocks, decoder blocks additionally insert cross-attention mod-\n",
      "ules between the multi-head self-attention modules and the position-\n",
      "wise FFNs. Furthermore, the self-attention modules in the decoder\n",
      "are adapted to prevent each position from attending to subsequent\n",
      "positions. The overall architecture of the vanilla Transformer is shown\n",
      "in Fig. 1.\n",
      "In the following subsection, we shall introduce the key modules of\n",
      "the vanilla Transformer.\n",
      "2.1.1. Attention modules\n",
      "Transformer adopts attention mechanism with Query–Key–Value\n",
      "(QKV) model. Given the packed matrix representations of queries 𝐐∈\n",
      "R𝑁×𝐷𝑘, keys 𝐊∈R𝑀×𝐷𝑘, and values 𝐕∈R𝑀×𝐷𝑣, the scaled dot-product\n",
      "attention used by Transformer is given by1\n",
      "Attention( 𝐐,𝐊,𝐕) = softmax(\n",
      "𝐐𝐊⊤\n",
      "√\n",
      "𝐷𝑘)\n",
      "𝐕=𝐀𝐕, (1)\n",
      "1If not stated otherwise, we use row-major notations throughout this survey\n",
      "(e.g., the𝑖th row in 𝐐is the query 𝐪𝑖) and all the vectors are row vectors by\n",
      "default.where𝑁and𝑀denote the lengths of queries and keys (or values);\n",
      "𝐷𝑘and𝐷𝑣denote the dimensions of keys (or queries) and values; 𝐀=\n",
      "softmax(\n",
      "𝐐𝐊⊤\n",
      "√\n",
      "𝐷𝑘)\n",
      "is often called attention matrix ; softmax is applied in a\n",
      "row-wise manner. The dot-products of queries and keys are divided by√\n",
      "𝐷𝑘to alleviate gradient vanishing problem of the softmax function.\n",
      "Instead of simply applying a single attention function, Transformer\n",
      "uses multi-head attention, where the 𝐷𝑚-dimensional original queries,\n",
      "keys and values are projected into 𝐷𝑘,𝐷𝑘and𝐷𝑣dimensions, re-\n",
      "spectively, with 𝐻different sets of learned projections. For each of\n",
      "the projected queries, keys and values, and output is computed with\n",
      "attention according to Eq. (1). The model then concatenates all the\n",
      "outputs and projects them back to a 𝐷𝑚-dimensional representation.\n",
      "MultiHeadAttn( 𝐐,𝐊,𝐕) = Concat(head1,…,head𝐻)𝐖𝑂, (2)\n",
      "where head𝑖= Attention( 𝐐𝐖𝑄\n",
      "𝑖,𝐊𝐖𝐾\n",
      "𝑖,𝐕𝐖𝑉\n",
      "𝑖). (3)\n",
      "In Transformer, there are three types of attention in terms of the\n",
      "source of queries and key–value pairs:\n",
      "•Self-attention . In Transformer encoder, we set 𝐐=𝐊=𝐕=𝐗in\n",
      "Eq. (2), where 𝐗is the outputs of the previous layer.\n",
      "•Masked Self-attention . In the Transformer decoder, the self-attention\n",
      "is restricted such that queries at each position can only attend to\n",
      "all key–value pairs up to and including that position. To enable\n",
      "parallel training, this is typically done by applying a mask func-\n",
      "tion to the unnormalized attention matrix ̂𝐀= exp(𝐐𝐊⊤\n",
      "√\n",
      "𝐷𝑘), where\n",
      "the illegal positions are masked out by setting ̂𝐴𝑖𝑗= −∞ if𝑖<𝑗.\n",
      "This kind of self-attention is often referred to as autoregressive or\n",
      "causal attention.2\n",
      "2This term seems to be borrowed from the causal system , where the output\n",
      "depends on past and current inputs but not future inputs.\n"
     ]
    }
   ],
   "source": [
    "print(single_page.page_content[0:5000])\n",
    "#we priented up to 5000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6012f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'transformers_survey.pdf', 'page': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d782b31",
   "metadata": {},
   "source": [
    "### Load Website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a396950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "Abrar Fahim        \n",
      "\n",
      "Abrar Fahim\n",
      " Data Scientist | Former KTP Associate \n",
      "Github Linkedin   Download CV  \n",
      "\n",
      "Highlights\n",
      "\n",
      "          - Data Scientist with experience in the HealthCare and FinTech industry \n",
      "          - Endorsed by UKRI, obtained a Global Talent Visa\n",
      "          - Solid Computer Science Background \n",
      "          - Experience in both Industry and Academic setup  \n",
      "\n",
      "Education Msc in Data Science and Analytics\n",
      "Bsc in Computer Science and Engineering Email abrar\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.abrarfahim.co.uk/\")\n",
    "docs = loader.load()\n",
    "print(docs[0].page_content[:500].replace(\"\\n\\n\\n\", \" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
